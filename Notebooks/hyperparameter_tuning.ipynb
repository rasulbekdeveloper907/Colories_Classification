{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd180cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Log fayl manzili\n",
    "log_path = r\"C:\\Users\\Rasulbek907\\Desktop\\Project_MP\\Log\\tuning.log\"\n",
    "\n",
    "# Log sozlamalari\n",
    "logging.basicConfig(\n",
    "    filename=log_path,\n",
    "    filemode='a',  # Append mode\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "try:\n",
    "    logging.info(\"CSV fayl o'qilmoqda:...\")\n",
    "    df = pd.read_csv(r\"C:\\Users\\Rasulbek907\\Desktop\\Project_MP\\Data\\Web_Scrapping\\openfoodfacts_fooddata.csv\")\n",
    "    logging.info(f\"Fayl muvaffaqiyatli o'qildi. Satƒ±rlar soni: {len(df)} ustunlar soni: {len(df.columns)}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"CSV faylni o'qishda xatolik: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbb85bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 40 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   code                5000 non-null   int64  \n",
      " 1   product_name        4761 non-null   object \n",
      " 2   brands              4730 non-null   object \n",
      " 3   categories          4914 non-null   object \n",
      " 4   countries           4998 non-null   object \n",
      " 5   quantity            4439 non-null   object \n",
      " 6   packaging           3424 non-null   object \n",
      " 7   energy_kcal         0 non-null      float64\n",
      " 8   fat                 0 non-null      float64\n",
      " 9   saturated_fat       0 non-null      float64\n",
      " 10  trans_fat           0 non-null      float64\n",
      " 11  cholesterol         0 non-null      float64\n",
      " 12  carbohydrates       0 non-null      float64\n",
      " 13  fiber               0 non-null      float64\n",
      " 14  proteins            0 non-null      float64\n",
      " 15  sugars              0 non-null      float64\n",
      " 16  salt                0 non-null      float64\n",
      " 17  sodium              0 non-null      float64\n",
      " 18  vitamin_a           0 non-null      float64\n",
      " 19  vitamin_c           0 non-null      float64\n",
      " 20  vitamin_d           0 non-null      float64\n",
      " 21  vitamin_e           0 non-null      float64\n",
      " 22  vitamin_b12         0 non-null      float64\n",
      " 23  iron                0 non-null      float64\n",
      " 24  calcium             0 non-null      float64\n",
      " 25  potassium           0 non-null      float64\n",
      " 26  zinc                0 non-null      float64\n",
      " 27  ingredients         0 non-null      float64\n",
      " 28  allergens           0 non-null      float64\n",
      " 29  traces              0 non-null      float64\n",
      " 30  additives           0 non-null      float64\n",
      " 31  nova_group          4506 non-null   float64\n",
      " 32  labels              0 non-null      float64\n",
      " 33  nutriscore          0 non-null      float64\n",
      " 34  ecoscore            0 non-null      float64\n",
      " 35  carbon_footprint    0 non-null      float64\n",
      " 36  environment_impact  0 non-null      float64\n",
      " 37  created_t           5000 non-null   int64  \n",
      " 38  last_modified_t     5000 non-null   int64  \n",
      " 39  languages           0 non-null      float64\n",
      "dtypes: float64(31), int64(3), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769ee100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Avvalgi ustunlar soni: 40\n",
      "üîπ Yangi (filtrlovdan keyingi) ustunlar soni: 10\n",
      "\n",
      "‚úÖ Quyidagi ustunlar qoldirildi:\n",
      "['code', 'product_name', 'brands', 'categories', 'countries', 'quantity', 'packaging', 'nova_group', 'created_t', 'last_modified_t']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 4000 dan kam non-null qiymatli ustunlarni tashlab yuborish\n",
    "df_filtered = df.loc[:, df.count() >= 2000]\n",
    "\n",
    "print(f\"üîπ Avvalgi ustunlar soni: {df.shape[1]}\")\n",
    "print(f\"üîπ Yangi (filtrlovdan keyingi) ustunlar soni: {df_filtered.shape[1]}\\n\")\n",
    "\n",
    "print(\"‚úÖ Quyidagi ustunlar qoldirildi:\")\n",
    "print(df_filtered.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932d40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(r\"C:\\Users\\Rasulbek907\\Desktop\\Project_MP\\Data\\Web_Scrapping\\Filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e8c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(r\"C:\\Users\\Rasulbek907\\Desktop\\Project_MP\\Data\\Web_Scrapping\\Filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca7e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       5000 non-null   int64  \n",
      " 1   code             5000 non-null   int64  \n",
      " 2   product_name     4761 non-null   object \n",
      " 3   brands           4730 non-null   object \n",
      " 4   categories       4914 non-null   object \n",
      " 5   countries        4998 non-null   object \n",
      " 6   quantity         4439 non-null   object \n",
      " 7   packaging        3424 non-null   object \n",
      " 8   nova_group       4506 non-null   float64\n",
      " 9   created_t        5000 non-null   int64  \n",
      " 10  last_modified_t  5000 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7564f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             product_name  nova_group health_level\n",
      "0                Sidi Ali         NaN      Unknown\n",
      "1                   perly         3.0    Processed\n",
      "2                Sidi Ali         1.0      Healthy\n",
      "3  Eau min√©rale naturelle         1.0      Healthy\n",
      "4                ÿßŸÉŸàÿßŸÅŸäŸÜÿß         NaN      Unknown\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Datasetni yuklash (sizda allaqachon mavjud)\n",
    "df = pd.read_csv(r\"C:\\Users\\Rasulbek907\\Desktop\\Project_MP\\Data\\Web_Scrapping\\Filtered.csv\")\n",
    "\n",
    "# Yangi 'health_level' ustunini yaratamiz\n",
    "def health_label(nova):\n",
    "    if nova == 1:\n",
    "        return \"Healthy\"\n",
    "    elif nova == 2:\n",
    "        return \"Medium\"\n",
    "    elif nova == 3:\n",
    "        return \"Processed\"\n",
    "    elif nova == 4:\n",
    "        return \"Unhealthy\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df[\"health_level\"] = df[\"nova_group\"].apply(health_label)\n",
    "\n",
    "# Natijani ko‚Äòramiz\n",
    "print(df[[\"product_name\", \"nova_group\", \"health_level\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16017c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       5000 non-null   int64  \n",
      " 1   code             5000 non-null   int64  \n",
      " 2   product_name     4761 non-null   object \n",
      " 3   brands           4730 non-null   object \n",
      " 4   categories       4914 non-null   object \n",
      " 5   countries        4998 non-null   object \n",
      " 6   quantity         4439 non-null   object \n",
      " 7   packaging        3424 non-null   object \n",
      " 8   nova_group       4506 non-null   float64\n",
      " 9   created_t        5000 non-null   int64  \n",
      " 10  last_modified_t  5000 non-null   int64  \n",
      " 11  health_level     5000 non-null   object \n",
      "dtypes: float64(1), int64(4), object(7)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954b25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'Processed', 'Healthy', 'Unhealthy', 'Medium'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"health_level\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9efe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0           code            product_name  \\\n",
      "0           0  6111035000430                Sidi Ali   \n",
      "1           1  6111242100992                   perly   \n",
      "2           2  6111035002175                Sidi Ali   \n",
      "3           3  6111035000058  Eau min√©rale naturelle   \n",
      "4           4  6111252421568                ÿßŸÉŸàÿßŸÅŸäŸÜÿß   \n",
      "\n",
      "                                 brands  \\\n",
      "0                              Sidi Ali   \n",
      "1                                 perly   \n",
      "2                              sidi ali   \n",
      "3  Les Eaux Min√©rales d'oulm√®s,Sidi Ali   \n",
      "4                              AQUAFINA   \n",
      "\n",
      "                                          categories              countries  \\\n",
      "0  Beverages and beverages preparations,Beverages...                Morocco   \n",
      "1                                             Snacks  Morocco,United States   \n",
      "2  Beverages and beverages preparations,Beverages...                Morocco   \n",
      "3  Beverages and beverages preparations,Beverages...                Morocco   \n",
      "4  Boissons et pr√©parations de boissons,Boissons,...                 ÿßŸÑŸÖÿ∫ÿ±ÿ®   \n",
      "\n",
      "  quantity                                packaging  nova_group   created_t  \\\n",
      "0    33 cl                          Plastic, Bottle         NaN  1439924914   \n",
      "1    100 g                                Plastique         3.0  1474037086   \n",
      "2      2 L                                      NaN         1.0  1537111522   \n",
      "3    1,5 L  Plastique,Bouteille ou Flacon,Bouteille         1.0  1409671459   \n",
      "4     33cl                    en:Plastic, en:Bottle         NaN  1553344271   \n",
      "\n",
      "   last_modified_t  health_level  \n",
      "0       1757170583             0  \n",
      "1       1761428815             3  \n",
      "2       1760896730             1  \n",
      "3       1761218197             1  \n",
      "4       1757702458             0  \n"
     ]
    }
   ],
   "source": [
    "# health_level qiymatlarini raqamli mapping qilish\n",
    "health_map = {\n",
    "    \"Unknown\": 0,\n",
    "    \"Healthy\": 1,\n",
    "    \"Medium\": 2,\n",
    "    \"Processed\": 3,\n",
    "    \"Unhealthy\": 4\n",
    "}\n",
    "\n",
    "df[\"health_level\"] = df[\"health_level\"].map(health_map)\n",
    "\n",
    "# Tekshiramiz\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934f163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Scripts\\python.exe\n",
      "Source path added: c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\Source\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Source papkasini yo'lga qo'shamiz\n",
    "source_path = os.path.abspath(\"../Source\")\n",
    "if source_path not in sys.path:\n",
    "    sys.path.append(source_path)\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Source path added:\", source_path)\n",
    "\n",
    "# Endi modulni import qilamiz\n",
    "from preprosessing import Cleaner, Encoder, Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f70b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = Cleaner(df)\n",
    "df = cleaner.tozala().get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f07fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       5000 non-null   int64  \n",
      " 1   code             5000 non-null   int64  \n",
      " 2   product_name     5000 non-null   object \n",
      " 3   brands           5000 non-null   object \n",
      " 4   categories       5000 non-null   object \n",
      " 5   countries        5000 non-null   object \n",
      " 6   quantity         5000 non-null   object \n",
      " 7   packaging        5000 non-null   object \n",
      " 8   nova_group       5000 non-null   float64\n",
      " 9   created_t        5000 non-null   int64  \n",
      " 10  last_modified_t  5000 non-null   int64  \n",
      " 11  health_level     5000 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(6)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bbc3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(df)\n",
    "df = encoder.encodla().get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1253441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       5000 non-null   int64  \n",
      " 1   code             5000 non-null   int64  \n",
      " 2   product_name     5000 non-null   int64  \n",
      " 3   brands           5000 non-null   int64  \n",
      " 4   categories       5000 non-null   int64  \n",
      " 5   countries        5000 non-null   int64  \n",
      " 6   quantity         5000 non-null   int64  \n",
      " 7   packaging        5000 non-null   int64  \n",
      " 8   nova_group       5000 non-null   float64\n",
      " 9   created_t        5000 non-null   int64  \n",
      " 10  last_modified_t  5000 non-null   int64  \n",
      " 11  health_level     5000 non-null   int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 468.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d773e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler(df, target_col=\"health_level\")\n",
    "scaled_df = scaler.scaling_qil().get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5d5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       5000 non-null   int64  \n",
      " 1   code             5000 non-null   int64  \n",
      " 2   product_name     5000 non-null   int64  \n",
      " 3   brands           5000 non-null   int64  \n",
      " 4   categories       5000 non-null   int64  \n",
      " 5   countries        5000 non-null   int64  \n",
      " 6   quantity         5000 non-null   int64  \n",
      " 7   packaging        5000 non-null   int64  \n",
      " 8   nova_group       5000 non-null   float64\n",
      " 9   created_t        5000 non-null   int64  \n",
      " 10  last_modified_t  5000 non-null   int64  \n",
      " 11  health_level     5000 non-null   int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 468.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d21edb",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb846721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Logistic Regression natijalari:\n",
      "Accuracy: 0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# X va y ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# Train / Test ajratish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Model yaratish\n",
    "log_model = LogisticRegression(max_iter=500, random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "print(\"üìä Logistic Regression natijalari:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3b151",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6c39072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≥ Decision Tree Classifier natijalari:\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# X va y ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# Train / Test ajratish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Model yaratish (default sozlamalar bilan)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# O‚Äòqitish\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Natijalar\n",
    "print(\"üå≥ Decision Tree Classifier natijalari:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a1a88",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "857c405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rf_model = RandomForestClassifier()  # default sozlamalar\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182921f7",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3574b",
   "metadata": {},
   "source": [
    "# MANUAL SEARCH "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d354303",
   "metadata": {},
   "source": [
    "# Description: Adjust hyperparameters by intuition or trial-and-error. # Pros: Simple # Cons: Inefficient, may miss optimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6487c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "829f1f71",
   "metadata": {},
   "source": [
    "#  RandomForestClassifier + Manual Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3381922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ Random Forest (Manual Search) Accuracy: 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# üß© Model (qo‚Äòlda hyperparameterlar bilan)\n",
    "rf_manual = RandomForestClassifier(\n",
    "    n_estimators=2,    # daraxtlar soni\n",
    "    max_depth=5,       # maksimal chuqurlik\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# O‚Äòqitish\n",
    "rf_manual.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred_manual = rf_manual.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "r2_manual = accuracy_score(y_test, y_pred_manual)\n",
    "print(\"üå≤ Random Forest (Manual Search) Accuracy:\", r2_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff5bac",
   "metadata": {},
   "source": [
    "#  DecisionTreeClassifier + Manual Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a4686e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≥ Decision Tree (Manual Search) Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# üå≥ Model ‚Äî qo‚Äòlda tanlangan hyperparametrlar bilan\n",
    "dt_manual = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",   # yoki \"gini\"\n",
    "    max_depth=5,           # maksimal chuqurlik\n",
    "    min_samples_split=4,   # bo‚Äòlinish uchun minimal namunalar\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# O‚Äòqitish\n",
    "dt_manual.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred_manual = dt_manual.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "acc_manual = accuracy_score(y_test, y_pred_manual)\n",
    "print(\"üå≥ Decision Tree (Manual Search) Accuracy:\", acc_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc17f43",
   "metadata": {},
   "source": [
    "#  LogisticRegression + Manual Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Logistic Regression (Manual Search) Accuracy: 0.5253333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "log_manual = LogisticRegression(\n",
    "    solver=\"liblinear\",   # kichik datasetlar uchun yaxshi\n",
    "    penalty=\"l2\",         # regularizatsiya turi (\"l1\" yoki \"l2\")\n",
    "    C=0.7,                # regularizatsiya kuchi (kichik bo‚Äòlsa ‚Äî ko‚Äòproq jazo)\n",
    "    max_iter=500,         # iteratsiyalar soni\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Modelni o‚Äòqitish\n",
    "log_manual.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred_manual = log_manual.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "acc_manual = accuracy_score(y_test, y_pred_manual)\n",
    "print(\"üìä Logistic Regression (Manual Search) Accuracy:\", acc_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de833907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffcd5c6b",
   "metadata": {},
   "source": [
    "# GRID SEARCH "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e464a",
   "metadata": {},
   "source": [
    "# RandomForestClassifier + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "765f4e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "üìà Random Forest (Grid Search) Accuracy: 1.0\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# üîç Grid Search uchun parametrlar to‚Äòplami\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],     # daraxtlar soni\n",
    "    'max_depth': [None, 5, 10, 15],     # daraxt chuqurligi\n",
    "    'min_samples_split': [2, 5, 10],    # bo‚Äòlinish uchun minimal namunalar\n",
    "    'min_samples_leaf': [1, 2, 4],      # barg tugunlari uchun minimal namunalar\n",
    "    'criterion': ['gini', 'entropy']    # ajratish mezoni\n",
    "}\n",
    "\n",
    "# üß† Grid Search sozlash\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                   # 5-fold cross validation\n",
    "    scoring='accuracy',     # aniqlikni baholash mezoni\n",
    "    n_jobs=-1,              # barcha yadroda bajarish\n",
    "    verbose=2               # jarayonni ko‚Äòrsatish\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish (eng yaxshi parametrlarni topish)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi model va parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüìà Random Forest (Grid Search) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeda0e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fac57b1",
   "metadata": {},
   "source": [
    "#  DecisionTreeClassifier + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f8539fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\n",
      "üå≥ Decision Tree (Grid Search) Accuracy: 1.0\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# üîç Grid Search uchun parametrlar to‚Äòplami\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # bo‚Äòlinish mezoni\n",
    "    'max_depth': [None, 5, 10, 20, 30],             # daraxt chuqurligi\n",
    "    'min_samples_split': [2, 5, 10],                # tugunni bo‚Äòlish uchun minimal namunalar\n",
    "    'min_samples_leaf': [1, 2, 4],                  # barg tugun uchun eng kam namunalar\n",
    "    'splitter': ['best', 'random']                  # tugun ajratish usuli\n",
    "}\n",
    "\n",
    "# üß† Grid Search sozlash\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüå≥ Decision Tree (Grid Search) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834aaeb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b97406",
   "metadata": {},
   "source": [
    "#  Logistic Regression + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fcdf310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "125 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 72, in _check_solver\n",
      "    raise ValueError(\n",
      "        f\"Only 'saga' solver supports elasticnet penalty, got solver={solver}.\"\n",
      "    )\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1228, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 77, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan 0.87457143 0.52571429 0.52657143 0.52228571 0.52571429\n",
      "        nan        nan        nan 0.52514286        nan 0.52571429\n",
      "        nan 0.88       0.52571429 0.52514286 0.52228571 0.52571429\n",
      "        nan        nan        nan 0.52514286        nan 0.52571429\n",
      "        nan 0.88       0.52571429 0.52514286 0.52228571 0.52571429\n",
      "        nan        nan        nan 0.52514286        nan 0.52571429\n",
      "        nan 0.88028571 0.52571429 0.52514286 0.52228571 0.52571429\n",
      "        nan        nan        nan 0.52514286        nan 0.52571429\n",
      "        nan 0.88085714 0.52571429 0.52514286 0.52228571 0.52571429\n",
      "        nan        nan        nan 0.52514286        nan 0.52571429]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "üìà Logistic Regression (Grid Search) Accuracy: 0.8853333333333333\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       0.00      0.00      0.00        64\n",
      "           3       0.68      0.92      0.78       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           0.89      1500\n",
      "   macro avg       0.68      0.67      0.67      1500\n",
      "weighted avg       0.86      0.89      0.86      1500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# üîç Grid Search uchun parametrlar to‚Äòplami\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],  # jarima turi\n",
    "    'C': [0.01, 0.1, 1, 10, 100],                 # regularizatsiya kuchi\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],     # optimallashtirish algoritmi\n",
    "}\n",
    "\n",
    "# üß† Grid Search sozlash\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',     # aniqlik mezoni\n",
    "    n_jobs=-1,              # barcha CPU yadrolarida bajarish\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß O‚Äòqitish\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_log_model = grid_search.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_log_model.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüìà Logistic Regression (Grid Search) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69ffe7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb292ba1",
   "metadata": {},
   "source": [
    "# RANDOM SEARCH "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f92bdb",
   "metadata": {},
   "source": [
    "# RandomForestClasssifier + Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "305a27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 120}\n",
      "\n",
      "üå≤ Random Forest (Random Search) Accuracy: 1.0\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint\n",
    "\n",
    "# üîπ Ma‚Äôlumotni ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# üîπ Train/Test bo‚Äòlish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# üå≤ Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# üéØ Random Search uchun parametrlar diapazoni\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),         # daraxtlar soni\n",
    "    'max_depth': [None, 5, 10, 20, 30],       # chuqurlik\n",
    "    'min_samples_split': randint(2, 10),      # bo‚Äòlinish uchun minimal namunalar\n",
    "    'min_samples_leaf': randint(1, 5),        # barg uchun minimal namunalar\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # ajratish mezoni\n",
    "    'bootstrap': [True, False]                # bootstrap namunalar ishlatilsinmi\n",
    "}\n",
    "\n",
    "# ‚öôÔ∏è Random Search sozlash\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,               # 20 ta tasodifiy kombinatsiyani sinaydi\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüå≤ Random Forest (Random Search) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e9ace",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc95aae3",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier + Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06d89519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'criterion': 'log_loss', 'max_depth': 20, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "\n",
      "üå≥ Decision Tree (Random Search) Accuracy: 1.0\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# üîπ X va y ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# üîπ Train/Test bo‚Äòlish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# üå≥ Model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# üéØ Random Search uchun parametrlar diapazoni\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],   # ajratish mezoni\n",
    "    'splitter': ['best', 'random'],                 # bo‚Äòlinish strategiyasi\n",
    "    'max_depth': [None, 5, 10, 20, 30, 50],         # daraxt chuqurligi\n",
    "    'min_samples_split': randint(2, 20),            # tugunni bo‚Äòlish uchun minimal namunalar\n",
    "    'min_samples_leaf': randint(1, 10),             # barg uchun minimal namunalar\n",
    "    'max_features': [None, 'sqrt', 'log2']          # xususiyat tanlash strategiyasi\n",
    "}\n",
    "\n",
    "# ‚öôÔ∏è Random Search sozlash\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,               # 20 ta kombinatsiya sinovdan o‚Äòtadi\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_dt_model = random_search.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüå≥ Decision Tree (Random Search) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92333f2",
   "metadata": {},
   "source": [
    "# Logistic regression + Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02e952a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 72, in _check_solver\n",
      "    raise ValueError(\n",
      "        f\"Only 'saga' solver supports elasticnet penalty, got solver={solver}.\"\n",
      "    )\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1228, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 77, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.52571429 0.25885714 0.88514286        nan\n",
      " 0.52571429        nan 0.52571429 0.52228571        nan        nan\n",
      "        nan 0.25885714 0.25885714 0.25885714        nan        nan\n",
      " 0.12              nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'C': np.float64(2.1333911067827613), 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "‚öôÔ∏è Logistic Regression (Random Search) Accuracy: 0.884\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       0.73      0.62      0.67        64\n",
      "           3       0.76      0.69      0.73       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           0.88      1500\n",
      "   macro avg       0.80      0.80      0.80      1500\n",
      "weighted avg       0.89      0.88      0.89      1500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# üîπ X va y ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# üîπ Train/Test ajratish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ‚öôÔ∏è Model\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# üéØ Random Search uchun parametrlar diapazoni\n",
    "param_dist = {\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],  # optimallashtirish algoritmlari\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],  # regularizatsiya turi\n",
    "    'C': uniform(0.01, 10),                     # regularizatsiya kuchi\n",
    "    'fit_intercept': [True, False],             # interceptni o‚Äòrganish yoki yo‚Äòq\n",
    "    'class_weight': [None, 'balanced']          # sinflarni balanslash\n",
    "}\n",
    "\n",
    "# üß† Random Search sozlash\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=log_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,               # 20 ta kombinatsiya sinovdan o‚Äòtadi\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_log_model = random_search.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_log_model.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\n‚öôÔ∏è Logistic Regression (Random Search) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b700de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0b8540a",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb558a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b672c",
   "metadata": {},
   "source": [
    "# Bayesian Optimization +  RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b203dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "‚úÖ Eng yaxshi parametrlar:\n",
      "OrderedDict({'bootstrap': True, 'max_depth': 23, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 154})\n",
      "\n",
      "üå≤ Random Forest (Bayesian Optimization) Accuracy: 1.0\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# üå≤ Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# üéØ Bayesian Optimization uchun parametrlar oralig‚Äòi\n",
    "param_space = {\n",
    "    'n_estimators': (50, 300),           # daraxtlar soni\n",
    "    'max_depth': (3, 30),                # chuqurlik\n",
    "    'min_samples_split': (2, 10),        # tugunni bo‚Äòlish uchun minimal namunalar\n",
    "    'min_samples_leaf': (1, 5),          # barg uchun minimal namunalar\n",
    "    'max_features': ['sqrt', 'log2', None], # xususiyat tanlash usuli\n",
    "    'bootstrap': [True, False]           # bootstrap namunalar ishlatilsinmi\n",
    "}\n",
    "\n",
    "# ‚öôÔ∏è BayesSearchCV sozlash\n",
    "opt = BayesSearchCV(\n",
    "    estimator=rf,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=25,              # necha kombinatsiya sinovdan o‚Äòtadi\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(opt.best_params_)\n",
    "\n",
    "# Eng yaxshi model\n",
    "best_rf = opt.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüå≤ Random Forest (Bayesian Optimization) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda6821",
   "metadata": {},
   "source": [
    "# Bayesian Optimization +  DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e868fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "‚úÖ Eng yaxshi parametrlar:\n",
      "OrderedDict({'criterion': 'entropy', 'max_depth': 22, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 14})\n",
      "\n",
      "üåø Decision Tree (Bayesian Optimization) Accuracy: 1.0\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# üîπ X va y ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# üîπ Train/Test ajratish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# üå≥ Model yaratish\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# üéØ Bayesian Optimization uchun parametrlar oralig‚Äòi\n",
    "param_space = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # qaror mezoni\n",
    "    'max_depth': (2, 30),                          # maksimal chuqurlik\n",
    "    'min_samples_split': (2, 20),                  # bo‚Äòlinish uchun minimal namunalar\n",
    "    'min_samples_leaf': (1, 10),                   # bargdagi minimal namunalar\n",
    "    'max_features': ['sqrt', 'log2', None]         # xususiyat tanlash strategiyasi\n",
    "}\n",
    "\n",
    "# ‚öôÔ∏è BayesSearchCV sozlash\n",
    "opt = BayesSearchCV(\n",
    "    estimator=dt,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=25,              # sinovlar soni\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# üîß Modelni o‚Äòqitish\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# üèÜ Eng yaxshi parametrlar\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(opt.best_params_)\n",
    "\n",
    "# Eng yaxshi modelni olish\n",
    "best_dt = opt.best_estimator_\n",
    "\n",
    "# Bashorat\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# üìä Natijalar\n",
    "print(\"\\nüåø Decision Tree (Bayesian Optimization) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df8f6e",
   "metadata": {},
   "source": [
    "# Bayesian Optimization +  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e4d29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Eng yaxshi parametrlar: OrderedDict({'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'})\n",
      "\n",
      "üìà Accuracy: 0.8853333333333333\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55       148\n",
      "           1       1.00      1.00      1.00       170\n",
      "           2       0.00      0.00      0.00        64\n",
      "           3       0.68      0.92      0.78       330\n",
      "           4       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           0.89      1500\n",
      "   macro avg       0.68      0.67      0.67      1500\n",
      "weighted avg       0.86      0.89      0.86      1500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# üîπ X va y\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ‚öôÔ∏è Model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# üîß Parametr oralig‚Äòi (mos juftliklar bilan)\n",
    "param_space = [\n",
    "    ({'solver': ['liblinear'], 'penalty': ['l1', 'l2'], 'C': (1e-4, 10.0, 'log-uniform')}),\n",
    "    ({'solver': ['lbfgs'], 'penalty': ['l2', None], 'C': (1e-4, 10.0, 'log-uniform')}),\n",
    "    ({'solver': ['saga'], 'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "      'C': (1e-4, 10.0, 'log-uniform'), 'l1_ratio': (0, 1.0)})\n",
    "]\n",
    "\n",
    "# üöÄ Bayesian Optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=log_reg,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\", opt.best_params_)\n",
    "best_model = opt.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nüìà Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5c5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21bfabbe",
   "metadata": {},
   "source": [
    "# Optuna (Automated / Advanced Method) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e497a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c55c0c8",
   "metadata": {},
   "source": [
    "# Optuna + Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda050f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Project_MP\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-10-29 14:24:21,997] A new study created in memory with name: no-name-59799a27-029e-4945-a029-3fa229808023\n",
      "[I 2025-10-29 14:24:24,227] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 299, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:25,894] Trial 1 finished with value: 0.9859990994976687 and parameters: {'n_estimators': 227, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:26,772] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 124, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:28,014] Trial 3 finished with value: 0.7740003713714728 and parameters: {'n_estimators': 241, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:29,046] Trial 4 finished with value: 0.9991431019708655 and parameters: {'n_estimators': 155, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:30,275] Trial 5 finished with value: 0.9757136285001639 and parameters: {'n_estimators': 197, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:31,808] Trial 6 finished with value: 0.9791424454566521 and parameters: {'n_estimators': 256, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:32,662] Trial 7 finished with value: 0.978571915007866 and parameters: {'n_estimators': 147, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:33,054] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 54, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:34,748] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 288, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:36,715] Trial 10 finished with value: 0.8588572831188149 and parameters: {'n_estimators': 299, 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:37,472] Trial 11 finished with value: 1.0 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:38,233] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 103, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:39,505] Trial 13 finished with value: 1.0 and parameters: {'n_estimators': 190, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:40,394] Trial 14 finished with value: 1.0 and parameters: {'n_estimators': 110, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:40,792] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:41,688] Trial 16 finished with value: 1.0 and parameters: {'n_estimators': 151, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:42,411] Trial 17 finished with value: 1.0 and parameters: {'n_estimators': 78, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:43,849] Trial 18 finished with value: 0.983428405410265 and parameters: {'n_estimators': 216, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:44,770] Trial 19 finished with value: 0.9737141997655167 and parameters: {'n_estimators': 131, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:46,518] Trial 20 finished with value: 1.0 and parameters: {'n_estimators': 269, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:47,012] Trial 21 finished with value: 1.0 and parameters: {'n_estimators': 59, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:47,696] Trial 22 finished with value: 1.0 and parameters: {'n_estimators': 74, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:48,430] Trial 23 finished with value: 1.0 and parameters: {'n_estimators': 88, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:49,641] Trial 24 finished with value: 1.0 and parameters: {'n_estimators': 174, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:50,613] Trial 25 finished with value: 1.0 and parameters: {'n_estimators': 125, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:51,813] Trial 26 finished with value: 1.0 and parameters: {'n_estimators': 177, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:52,614] Trial 27 finished with value: 1.0 and parameters: {'n_estimators': 97, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:53,055] Trial 28 finished with value: 0.9805725685824633 and parameters: {'n_estimators': 66, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:24:53,864] Trial 29 finished with value: 0.9874275078475495 and parameters: {'n_estimators': 126, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü•á Eng yaxshi parametrlar:\n",
      "{'n_estimators': 299, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}\n",
      "‚úÖ Eng yaxshi aniqlik (CV): 1.0000\n",
      "üéØ Test aniqligi: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# üîπ X va y ajratish\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# üîπ Train/test bo‚Äòlish (stratify bilan)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# üîπ Optuna maqsad funksiyasi\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 3-fold cross-validation orqali aniqlikni o‚Äòlchash\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    return score\n",
    "\n",
    "# üîπ Study yaratish\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# üîπ Natijalar\n",
    "print(\"ü•á Eng yaxshi parametrlar:\")\n",
    "print(study.best_params)\n",
    "print(f\"‚úÖ Eng yaxshi aniqlik (CV): {study.best_value:.4f}\")\n",
    "\n",
    "# üîπ Eng yaxshi modelni yaratish va testda sinovdan o‚Äòtkazish\n",
    "best_model = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"üéØ Test aniqligi: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5bef4",
   "metadata": {},
   "source": [
    "# Optuna + Decision Tree  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51ddc59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-29 14:25:02,132] A new study created in memory with name: no-name-893e72d0-4c15-4aad-a368-90cbb915bfa5\n",
      "[I 2025-10-29 14:25:02,177] Trial 0 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 9, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,212] Trial 1 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 5, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,231] Trial 2 finished with value: 0.9011429226542967 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 3, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,251] Trial 3 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 4, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,284] Trial 4 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 19, 'min_samples_leaf': 4, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,302] Trial 5 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 5, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,346] Trial 6 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,390] Trial 7 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,408] Trial 8 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 5, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,452] Trial 9 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 2, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,492] Trial 10 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 20, 'min_samples_leaf': 10, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,535] Trial 11 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 7, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,579] Trial 12 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 16, 'min_samples_leaf': 8, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,619] Trial 13 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 1, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,664] Trial 14 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 7, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,713] Trial 15 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 10, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,751] Trial 16 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 12, 'min_samples_leaf': 8, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,796] Trial 17 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 6, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,822] Trial 18 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 8, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,880] Trial 19 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 4, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,918] Trial 20 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 12, 'min_samples_leaf': 7, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,948] Trial 21 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 4, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:02,975] Trial 22 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 3, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,003] Trial 23 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 5, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,035] Trial 24 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 3, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,065] Trial 25 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,096] Trial 26 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 2, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,138] Trial 27 finished with value: 1.0 and parameters: {'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 4, 'splitter': 'best'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,169] Trial 28 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 5, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-10-29 14:25:03,199] Trial 29 finished with value: 0.9011429226542967 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 9, 'splitter': 'random'}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ Eng yaxshi parametrlar:\n",
      "{'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 9, 'splitter': 'best'}\n",
      "‚úÖ Eng yaxshi aniqlik (CV): 1.0000\n",
      "üéØ Test aniqligi: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# üîπ X va y\n",
    "X = df.drop(columns=\"health_level\")\n",
    "y = df[\"health_level\"]\n",
    "\n",
    "# üîπ Train / Test bo‚Äòlish\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# üîπ Optuna maqsad funksiyasi\n",
    "def objective(trial):\n",
    "    # Parametrlarni tanlash\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    splitter = trial.suggest_categorical(\"splitter\", [\"best\", \"random\"])\n",
    "\n",
    "    # Model yaratish\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        splitter=splitter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross-validation orqali baholash\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    return score\n",
    "\n",
    "# üîπ Optuna study yaratish\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# üîπ Natijalarni chiqarish\n",
    "print(\"üå≤ Eng yaxshi parametrlar:\")\n",
    "print(study.best_params)\n",
    "print(f\"‚úÖ Eng yaxshi aniqlik (CV): {study.best_value:.4f}\")\n",
    "\n",
    "# üîπ Eng yaxshi modelni testda sinash\n",
    "best_model = DecisionTreeClassifier(**study.best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"üéØ Test aniqligi: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9463bc",
   "metadata": {},
   "source": [
    "# Optuna + Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a95bbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-29 14:25:35,918] A new study created in memory with name: no-name-0b388add-7b20-43e8-90f4-ca72f44d3e48\n",
      "[I 2025-10-29 14:25:36,017] Trial 0 finished with value: 0.9065714285714286 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 32, 'min_samples_split': 14, 'min_samples_leaf': 15, 'max_features': 'log2'}. Best is trial 0 with value: 0.9065714285714286.\n",
      "[I 2025-10-29 14:25:36,107] Trial 1 finished with value: 0.9357142857142857 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 45, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9357142857142857.\n",
      "[I 2025-10-29 14:25:36,160] Trial 2 finished with value: 0.858 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 1 with value: 0.9357142857142857.\n",
      "[I 2025-10-29 14:25:36,248] Trial 3 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 46, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,281] Trial 4 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,314] Trial 5 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,367] Trial 6 finished with value: 0.9037142857142857 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,443] Trial 7 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,516] Trial 8 finished with value: 0.9299999999999999 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 34, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,565] Trial 9 finished with value: 0.9148571428571428 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 16, 'min_samples_split': 19, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,601] Trial 10 finished with value: 0.8785714285714287 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 15, 'max_features': 'sqrt'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,637] Trial 11 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,676] Trial 12 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 38, 'min_samples_split': 14, 'min_samples_leaf': 19, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,717] Trial 13 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 29, 'min_samples_split': 20, 'min_samples_leaf': 11, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,806] Trial 14 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 13, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,842] Trial 15 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 49, 'min_samples_split': 12, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,934] Trial 16 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 40, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:36,978] Trial 17 finished with value: 0.8354285714285714 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 23, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': 'sqrt'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,018] Trial 18 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 37, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,108] Trial 19 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 14, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,156] Trial 20 finished with value: 0.8591428571428571 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 45, 'min_samples_split': 13, 'min_samples_leaf': 17, 'max_features': 'sqrt'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,193] Trial 21 finished with value: 0.6957142857142857 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,240] Trial 22 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,284] Trial 23 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,321] Trial 24 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,363] Trial 25 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 18, 'min_samples_split': 11, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,453] Trial 26 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 35, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,493] Trial 27 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,571] Trial 28 finished with value: 0.9460000000000001 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 28, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,649] Trial 29 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 33, 'min_samples_split': 13, 'min_samples_leaf': 15, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,687] Trial 30 finished with value: 0.6722857142857143 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 11, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,769] Trial 31 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,851] Trial 32 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:37,935] Trial 33 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 45, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,066] Trial 34 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,138] Trial 35 finished with value: 0.9511428571428571 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 31, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,222] Trial 36 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,294] Trial 37 finished with value: 0.9291428571428572 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,344] Trial 38 finished with value: 0.9497142857142856 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,382] Trial 39 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 36, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,419] Trial 40 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 40, 'min_samples_split': 20, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,458] Trial 41 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 42, 'min_samples_split': 15, 'min_samples_leaf': 13, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,496] Trial 42 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 47, 'min_samples_split': 19, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,531] Trial 43 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 50, 'min_samples_split': 18, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,567] Trial 44 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 40, 'min_samples_split': 15, 'min_samples_leaf': 11, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,604] Trial 45 finished with value: 0.8480000000000001 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 38, 'min_samples_split': 12, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,684] Trial 46 finished with value: 1.0 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 16, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,719] Trial 47 finished with value: 0.8671428571428572 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 43, 'min_samples_split': 14, 'min_samples_leaf': 13, 'max_features': 'sqrt'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,757] Trial 48 finished with value: 1.0 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-10-29 14:25:38,819] Trial 49 finished with value: 1.0 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 38, 'min_samples_split': 18, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 3 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Eng yaxshi parametrlar:\n",
      "{'criterion': 'entropy', 'splitter': 'best', 'max_depth': 46, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "\n",
      "üå≥ Optuna + DecisionTreeClassifier Accuracy: 1.000\n",
      "\n",
      "üîç To‚Äòliq tahlil:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       168\n",
      "           1       1.00      1.00      1.00       165\n",
      "           2       1.00      1.00      1.00        55\n",
      "           3       1.00      1.00      1.00       360\n",
      "           4       1.00      1.00      1.00       752\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ma'lumotni bo'lish\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- Objective function for Optuna ---\n",
    "def objective(trial):\n",
    "    # Hiperparametrlar uchun qidiruv oralig'i\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    splitter = trial.suggest_categorical(\"splitter\", [\"best\", \"random\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"])\n",
    "\n",
    "    # Model yaratish\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        splitter=splitter,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# --- Optuna optimization ---\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"‚úÖ Eng yaxshi parametrlar:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# --- Yakuniy modelni qurish ---\n",
    "best_params = study.best_params\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Baholash ---\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüå≥ Optuna + DecisionTreeClassifier Accuracy: {acc:.3f}\")\n",
    "print(\"\\nüîç To‚Äòliq tahlil:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93db55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
