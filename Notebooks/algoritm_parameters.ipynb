{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2f4ece",
   "metadata": {},
   "source": [
    "# HYPERPARAMAETERS FOR ALGORITMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d89960",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 1. Linear Regression\n",
    "ğŸ“š `sklearn.linear_model.LinearRegression`\n",
    "\n",
    "| Hyperparameter | Tavsifi | Tavsiya qiymatlari | Natijaga taâ€™siri |\n",
    "|----------------|----------|--------------------|------------------|\n",
    "| `fit_intercept` | Intercept (bâ‚€)ni oâ€˜rganish | True / False | False â†’ chiziq koordinata boshidan oâ€˜tadi |\n",
    "| `positive` | Koeffitsientlar manfiy boâ€˜lmasin | True / False | True â†’ faqat musbat ogâ€˜irliklar boâ€˜ladi |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3b8c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c277237",
   "metadata": {},
   "source": [
    "## ğŸ”¹ Logistic Regression  \n",
    "ğŸ“š `sklearn.linear_model.LogisticRegression`\n",
    "\n",
    "| Hyperparameter | Tavsifi | Tavsiya qiymatlari | Natijaga taâ€™siri |\n",
    "|----------------|----------|--------------------|------------------|\n",
    "| `C` | Regularizatsiya kuchi (1/Î») â€” overfittingni boshqaradi | 0.01 â€“ 100 | Kichik C â†’ kuchli regularizatsiya, overfitting kamayadi |\n",
    "| `penalty` | Regularizatsiya turi (jazolash usuli) | `'l1'`, `'l2'`, `'elasticnet'`, `'none'` | `l1` â†’ sparse, `l2` â†’ silliq ogâ€˜irliklar |\n",
    "| `solver` | Optimallashtirish algoritmi | `'lbfgs'`, `'liblinear'`, `'saga'` | Katta dataset â†’ `'lbfgs'`, kichik â†’ `'liblinear'` |\n",
    "| `max_iter` | Maksimal iteratsiyalar soni | 100 â€“ 1000 | Yetarli boâ€˜lmasa, â€œConvergenceWarningâ€ xatosi chiqadi |\n",
    "| `class_weight` | Sinf balansini hisobga olish | `'balanced'` yoki `{0:1, 1:5}` | `balanced` â†’ sinflar tenglashtiriladi |\n",
    "| `random_state` | Tasodifiylikni nazorat qiladi | 42 yoki istalgan butun son | Barqaror natija uchun kerak |\n",
    "\n",
    "**Kod misol:**\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression modeli\n",
    "model = LogisticRegression(\n",
    "    C=1.0, \n",
    "    penalty='l2', \n",
    "    solver='lbfgs', \n",
    "    max_iter=200, \n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b837543",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74dcdb02",
   "metadata": {},
   "source": [
    "## ğŸ”¹ Decision Tree  \n",
    "ğŸ“š `sklearn.tree.DecisionTreeClassifier`\n",
    "\n",
    "| Hyperparameter | Tavsifi | Tavsiya qiymatlari | Natijaga taâ€™siri |\n",
    "|----------------|----------|--------------------|------------------|\n",
    "| `criterion` | Tugunlarni baholash mezoni | `'gini'`, `'entropy'`, `'log_loss'` | `entropy` â†’ aniqlik yuqori, lekin sekinroq |\n",
    "| `max_depth` | Daraxt chuqurligi | 3 â€“ 30 | Katta â†’ overfitting, kichik â†’ underfitting |\n",
    "| `min_samples_split` | Boâ€˜linish uchun minimal namuna soni | 2 â€“ 20 | Katta â†’ daraxt soddalashadi |\n",
    "| `min_samples_leaf` | Bargdagi minimal namunalar soni | 1 â€“ 10 | Barglarni silliqlashtiradi |\n",
    "| `splitter` | Boâ€˜linish strategiyasi | `'best'`, `'random'` | `random` â†’ umumlashtirishni yaxshilaydi |\n",
    "| `class_weight` | Sinf balansini hisobga olish | `'balanced'` yoki `{0:1, 1:5}` | Disbalansli datasetlarda foydali |\n",
    "\n",
    "**Kod misol:**\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb755b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31910920",
   "metadata": {},
   "source": [
    "# ğŸŒ² Random Forest Classifier â€” Toâ€˜liq Darslik\n",
    "\n",
    "ğŸ“˜ **Kutubxona:** `sklearn.ensemble.RandomForestClassifier`  \n",
    "ğŸ“Š **Model turi:** Ensemble (Bagging-based)  \n",
    "ğŸ’¡ **Asosiy gâ€˜oya:** Bir nechta Decision Tree modellarini oâ€˜rtacha natija olish uchun birlashtirish. Har bir daraxt â€” tasodifiy xususiyatlar va namunalar asosida oâ€˜qitiladi.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Asosiy Gâ€˜oya\n",
    "Random Forest â€” bu **koâ€˜p sonli mustaqil qaror daraxtlari (Decision Trees)** dan iborat ansambl model.  \n",
    "Har bir daraxt:\n",
    "- Datasetdan **tasodifiy namunalar (bootstrap sampling)** oladi  \n",
    "- Har boâ€˜linishda **tasodifiy xususiyatlar** tanlaydi  \n",
    "\n",
    "Natijada:\n",
    "- Overfitting kamayadi  \n",
    "- Barqaror va yuqori aniqlikka ega model hosil boâ€˜ladi\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Hyperparameter Jadvali\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Natijaga taâ€™siri |\n",
    "|-----------|---------|-------------------|------------------|\n",
    "| `n_estimators` | Daraxtlar soni | 100â€“500 | Katta boâ€˜lsa â€” aniqlik oshadi, lekin sekin ishlaydi |\n",
    "| `max_depth` | Har daraxtning chuqurligi | 5â€“30 | Cheklash â†’ overfitting kamayadi |\n",
    "| `min_samples_split` | Boâ€˜linish uchun minimal namunalar soni | 2â€“10 | Katta boâ€˜lsa â†’ model soddalashadi |\n",
    "| `min_samples_leaf` | Bargdagi minimal namunalar soni | 1â€“10 | Silliq qaror chegaralarini yaratadi |\n",
    "| `max_features` | Boâ€˜linishda ishlatiladigan xususiyatlar soni | `'sqrt'`, `'log2'`, int | Diversifikatsiyani oshiradi |\n",
    "| `bootstrap` | Daraxtlar bootstrap orqali oâ€˜qitiladimi | `True` / `False` | `True` â†’ turgâ€˜unroq model |\n",
    "| `criterion` | Boâ€˜linish mezoni | `'gini'` / `'entropy'` / `'log_loss'` | `entropy` â†’ sekin, lekin aniqlik yuqori |\n",
    "| `class_weight` | Sinf balansini hisobga olish | `'balanced'`, `{0:1, 1:5}` | Imbalanced datasetlarda foydali |\n",
    "| `random_state` | Natijani barqarorlashtirish | int (masalan, 42) | Reproducibility taâ€™minlaydi |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Ma'lumotlarni tayyorlash\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model yaratish\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Modelni oâ€˜qitish\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3d232",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c7214f",
   "metadata": {},
   "source": [
    "# âš™ï¸ Support Vector Machine (SVM) â€” Toâ€˜liq Darslik\n",
    "\n",
    "ğŸ“˜ **Kutubxona:** `sklearn.svm.SVC`  \n",
    "ğŸ“Š **Model turi:** Klassifikatsiya (hamda regressiya uchun `SVR`)  \n",
    "ğŸ’¡ **Asosiy gâ€˜oya:** Maâ€™lumotlarni **chegaralovchi optimal gipertekislik (hyperplane)** orqali ajratish.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  SVM nima?\n",
    "\n",
    "SVM â€” maâ€™lumotlarni shunday chiziq (yoki tekislik) orqali ajratadiki, bu chiziq **har ikki sinfga eng uzoq** boâ€˜ladi.  \n",
    "Boshqacha aytganda, **margin** (yaâ€™ni sinflar orasidagi masofa) maksimal qilinadi.\n",
    "\n",
    "SVM quyidagilarni qoâ€˜llab-quvvatlaydi:\n",
    "- Linear ajraluvchi maâ€™lumotlar (`kernel='linear'`)\n",
    "- Nolinear ajraluvchi maâ€™lumotlar (`kernel='rbf'`, `'poly'`, `'sigmoid'`)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Hyperparameter Jadvali\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Natijaga taâ€™siri |\n",
    "|-----------|---------|-------------------|------------------|\n",
    "| `C` | Regularizatsiya koeffitsienti (1/Î») | 0.1 â€“ 100 | Katta C â†’ kam xatolikka yoâ€˜l qoâ€˜yadi, lekin overfitting mumkin |\n",
    "| `kernel` | Kernel funksiyasi turi | `'linear'`, `'poly'`, `'rbf'`, `'sigmoid'` | Modelning murakkabligini belgilaydi |\n",
    "| `degree` | Polynomial kernel darajasi (`kernel='poly'` uchun) | 2â€“5 | Yuqori daraja â†’ murakkab model |\n",
    "| `gamma` | Kernel tarqalishini boshqaradi (`'rbf'`, `'poly'`, `'sigmoid'`) | `'scale'`, `'auto'`, yoki float | Katta gamma â†’ yaqin nuqtalarga eâ€™tibor, overfitting xavfi |\n",
    "| `coef0` | `poly` va `sigmoid` kernel uchun doimiy qoâ€˜shiluvchi qiymat | 0â€“1 | Kichik oâ€˜zgarishlarda taâ€™siri kam, ammo murakkab kernelda sezilarli |\n",
    "| `class_weight` | Sinflar balansini hisobga olish | `'balanced'`, `{0:1, 1:3}` | Nomutanosib datasetlarda ishlatish kerak |\n",
    "| `shrinking` | â€œShrinking heuristicâ€ni yoqish | True / False | True â†’ tezroq, odatda barqaror |\n",
    "| `probability` | Ehtimollik hisoblashni yoqish | True / False | True â†’ `predict_proba()` ishlaydi, lekin sekinroq |\n",
    "| `max_iter` | Maksimal iteratsiyalar soni | -1 (cheksiz) yoki 1000â€“5000 | Yetarli boâ€˜lmasa, konvergentsiya xatosi chiqadi |\n",
    "| `random_state` | Tasodifiylikni nazorat qiladi | int (masalan, 42) | Barqaror natijalar uchun |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ma'lumotlarni yuklash\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model yaratish\n",
    "model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    class_weight='balanced',\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Oâ€˜qitish\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Natijalarni baholash\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc505b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602dee17",
   "metadata": {},
   "source": [
    "# ğŸ‘¥ K-Nearest Neighbors (KNN) â€” Toâ€˜liq Darslik\n",
    "\n",
    "ğŸ“˜ **Kutubxona:** `sklearn.neighbors.KNeighborsClassifier`  \n",
    "ğŸ“Š **Model turi:** Klassifikatsiya (regressiya uchun `KNeighborsRegressor`)  \n",
    "ğŸ’¡ **Asosiy gâ€˜oya:** Yangi nuqtaning sinfi â€” unga eng yaqin boâ€˜lgan `k` ta qoâ€˜shnining ovozlari asosida aniqlanadi.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  KNN nima?\n",
    "\n",
    "KNN â€” bu **lazy learning (sust oâ€˜rganuvchi)** algoritm.  \n",
    "Yaâ€™ni, u modelni oâ€˜qitmaydi, faqat **xotirada maâ€™lumotlarni saqlab**, yangi namunani sinflashtirishda masofa oâ€˜lchovlari orqali qaror qabul qiladi.\n",
    "\n",
    "- Oâ€˜qitish â†’ juda tez (hech narsa oâ€˜rganmaydi)  \n",
    "- Bashorat â†’ sekin (har safar barcha nuqtalar bilan masofa hisoblaydi)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Hyperparameter Jadvali\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Natijaga taâ€™siri |\n",
    "|-----------|---------|-------------------|------------------|\n",
    "| `n_neighbors` | Eng yaqin qoâ€˜shnilar soni (`k`) | 3â€“15 | Katta `k` â†’ silliq qarorlar, lekin underfitting mumkin |\n",
    "| `weights` | Qoâ€˜shnilarning ogâ€˜irligi | `'uniform'` yoki `'distance'` | `'distance'` â†’ yaqin nuqtalarga koâ€˜proq ogâ€˜irlik |\n",
    "| `metric` | Masofa turi | `'minkowski'`, `'euclidean'`, `'manhattan'` | Qanday masofa oâ€˜lchanishini belgilaydi |\n",
    "| `p` | Minkowski uchun daraja (`p=1` â†’ manhattan, `p=2` â†’ euclidean) | 1 yoki 2 | Odatda 2 (evklid masofa) |\n",
    "| `algorithm` | Masofa qidirish usuli | `'auto'`, `'ball_tree'`, `'kd_tree'`, `'brute'` | Katta datasetda tezlikni belgilaydi |\n",
    "| `leaf_size` | KDTree/BallTree uchun barg hajmi | 20â€“50 | Tezlikka taâ€™sir qiladi, natijaga uncha emas |\n",
    "| `n_jobs` | Paralel hisoblash yadrolari soni | -1 (barcha yadro) | Hisoblash tezligini oshiradi |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ma'lumotlarni yuklash\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model yaratish\n",
    "model = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='distance',\n",
    "    metric='minkowski',\n",
    "    p=2,\n",
    "    algorithm='auto',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Oâ€˜qitish (maâ€™lumotni saqlaydi)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Bashorat\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f32788",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e8090f",
   "metadata": {},
   "source": [
    "# ğŸš€ XGBoost (Extreme Gradient Boosting) â€” Toâ€˜liq Darslik\n",
    "\n",
    "ğŸ“˜ **Kutubxona:** `xgboost.XGBClassifier`  \n",
    "ğŸ“Š **Model turi:** Ensemble â€” Gradient Boosting asosida  \n",
    "ğŸ’¡ **Asosiy gâ€˜oya:** Har bir yangi daraxt avvalgi modelning xatolarini tuzatadi.  \n",
    "Natijada â€” juda aniqlik yuqori, barqaror model hosil boâ€˜ladi.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  XGBoost nima?\n",
    "\n",
    "XGBoost â€” **Gradient Boosting** algoritmining takomillashtirilgan, tezkor va samarali versiyasi.  \n",
    "U quyidagilarni yaxshilaydi:\n",
    "- Regularizatsiya (L1 va L2)\n",
    "- Paralel oâ€˜qitish\n",
    "- Missing valueâ€™larni avtomatik boshqarish\n",
    "- Tree pruning va early stopping\n",
    "\n",
    "Asosiy maqsad:  \n",
    "Har bir yangi daraxt, oldingi modelning xatolarini **gradient** asosida tuzatadi.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Hyperparameter Jadvali\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Natijaga taâ€™siri |\n",
    "|-----------|---------|-------------------|------------------|\n",
    "| `n_estimators` | Daraxtlar soni | 100â€“1000 | Katta boâ€˜lsa â†’ aniqlik oshadi, lekin sekin ishlaydi |\n",
    "| `learning_rate` | Har bir daraxtning hissasi (Î·) | 0.01â€“0.3 | Kichik â†’ sekin oâ€˜rganish, barqaror model |\n",
    "| `max_depth` | Har bir daraxt chuqurligi | 3â€“10 | Katta boâ€˜lsa â†’ overfitting xavfi |\n",
    "| `min_child_weight` | Boâ€˜linish uchun minimal ogâ€˜irlik | 1â€“10 | Katta â†’ konservativ model |\n",
    "| `subsample` | Har iteratsiyada ishlatiladigan namunalar foizi | 0.5â€“1.0 | Kichik â†’ overfitting kamayadi |\n",
    "| `colsample_bytree` | Har daraxtda ishlatiladigan ustunlar foizi | 0.5â€“1.0 | Modelning barqarorligini oshiradi |\n",
    "| `gamma` | Boâ€˜linish uchun minimal foyda | 0â€“10 | Katta â†’ kam boâ€˜linish, soddaroq model |\n",
    "| `reg_alpha` | L1 regularizatsiya (Lasso) | 0â€“10 | Sparse model yaratadi |\n",
    "| `reg_lambda` | L2 regularizatsiya (Ridge) | 0â€“10 | Modelni silliqlashtiradi |\n",
    "| `scale_pos_weight` | Sinf disbalansini hisobga olish | 1, 5, 10 | Imbalanced dataset uchun foydali |\n",
    "| `random_state` | Tasodifiylik nazorati | int (masalan, 42) | Natijani takrorlash imkonini beradi |\n",
    "| `early_stopping_rounds` | Oâ€˜qitishni toâ€˜xtatish sharti | 10â€“50 | Val. aniqlik oshmasa â€” trening toâ€˜xtaydi |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ma'lumotlarni yuklash\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model yaratish\n",
    "model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Modelni oâ€˜qitish\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "# Bashorat\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Baholash\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a035d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11225b85",
   "metadata": {},
   "source": [
    "# âš¡ Boosting Oilasi â€” Toâ€˜liq Darslik (AdaBoost, GradientBoosting, LightGBM, CatBoost)\n",
    "\n",
    "ğŸ“˜ **Mavzu:** Ensemble Learning â†’ Boosting algoritmlari  \n",
    "ğŸ§  **Asosiy gâ€˜oya:** Har bir yangi model oldingilarning xatolarini tuzatadi.  \n",
    "ğŸ¯ **Maqsad:** Kuchsiz oâ€˜rganuvchilar (weak learners)dan kuchli model yaratish.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 1. AdaBoost (Adaptive Boosting)\n",
    "\n",
    "ğŸ“š `from sklearn.ensemble import AdaBoostClassifier`\n",
    "\n",
    "### ğŸ§© Tavsif\n",
    "AdaBoost â€” **birinchi Boosting** algoritmi.  \n",
    "U **Decision Tree (max_depth=1)** asosidagi bir nechta â€œkuchsizâ€ modellardan foydalanadi.  \n",
    "Har iteratsiyada xatolar uchun ogâ€˜irlikni oshirib, muhim namunalarni â€œkoâ€˜proq oâ€˜rganadiâ€.\n",
    "\n",
    "### âš™ï¸ Hyperparametrlar\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Taâ€™siri |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| `n_estimators` | Kuchsiz modellar soni | 50â€“500 | Koâ€˜p boâ€˜lsa â€” aniqlik oshadi, lekin sekinlashadi |\n",
    "| `learning_rate` | Har model hissasi | 0.01â€“1.0 | Katta â†’ tez oâ€˜rganadi, lekin overfitting xavfi |\n",
    "| `estimator` | Asosiy model (odatda DecisionTreeClassifier) | Default: stump | Murakkab daraxt â†’ kuchliroq model |\n",
    "| `random_state` | Tasodifiylik nazorati | int | Takrorlanadigan natija |\n",
    "\n",
    "### ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147a9a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed697bcc",
   "metadata": {},
   "source": [
    "# ğŸŒ² Gradient Boosting (GBM) â€” Toâ€˜liq Darslik\n",
    "\n",
    "ğŸ“š **Kutubxona:** `sklearn.ensemble.GradientBoostingClassifier`  \n",
    "ğŸ’¡ **Turi:** Ensemble (Boosting oilasi)  \n",
    "ğŸ¯ **Maqsad:** Oldingi modellar xatolarini gradient asosida tuzatish orqali aniqlikni oshirish.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Asosiy gâ€˜oya\n",
    "\n",
    "Gradient Boosting â€” bu ketma-ket oâ€˜rganadigan ansambl boâ€˜lib,  \n",
    "har bir yangi daraxt avvalgi modelning **xatolarini gradient (yoâ€˜nalish) boâ€˜yicha tuzatadi**.\n",
    "\n",
    "Har bir iteratsiyada:\n",
    "\\[\n",
    "F_m(x) = F_{m-1}(x) + \\eta \\cdot h_m(x)\n",
    "\\]\n",
    "bu yerda  \n",
    "- \\(F_{m-1}\\) â€” oldingi model,  \n",
    "- \\(h_m\\) â€” yangi daraxt,  \n",
    "- \\(\\eta\\) â€” learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Muhim Hyperparametrlar\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Natijaga taâ€™siri |\n",
    "|-----------|---------|-------------------|------------------|\n",
    "| `n_estimators` | Daraxtlar soni | 100â€“1000 | Koâ€˜p â†’ aniqlik oshadi, lekin sekinlashadi |\n",
    "| `learning_rate` | Oâ€˜rganish tezligi | 0.01â€“0.3 | Kichik â†’ barqaror, katta â†’ overfitting xavfi |\n",
    "| `max_depth` | Har daraxt chuqurligi | 3â€“10 | Katta â†’ overfitting |\n",
    "| `min_samples_split` | Tugunni boâ€˜lish uchun minimal namuna soni | 2â€“10 | Katta â†’ soddaroq model |\n",
    "| `min_samples_leaf` | Bargdagi eng kam namuna soni | 1â€“10 | Katta â†’ silliq model |\n",
    "| `subsample` | Har iteratsiyada ishlatiladigan namunalar ulushi | 0.5â€“1.0 | Kichik â†’ regularizatsiya |\n",
    "| `max_features` | Har daraxt uchun ustunlar soni | 'sqrt', 'log2', None | Model xilma-xilligini oshiradi |\n",
    "| `random_state` | Tasodifiylik nazorati | int (masalan 42) | Takrorlanadigan natijalar |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ma'lumot\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Oâ€˜qitish\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Natija\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce600e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe5f7402",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ“˜ 2. LightGBM (Microsoft)\n",
    "\n",
    "```markdown\n",
    "# ğŸš€ LightGBM (Microsoft) â€” Toâ€˜liq Darslik\n",
    "\n",
    "ğŸ“š **Kutubxona:** `lightgbm.LGBMClassifier`  \n",
    "ğŸ’¡ **Turi:** Gradient Boosting (GBDT) oilasi  \n",
    "âš™ï¸ **Tuzuvchi:** Microsoft  \n",
    "ğŸ¯ **Asosiy maqsad:** Katta datasetlar uchun juda tez va xotira tejamkor boosting modeli.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Asosiy gâ€˜oya\n",
    "\n",
    "LightGBM â€” **Gradient Boosted Decision Tree (GBDT)**â€™ning optimallashtirilgan versiyasi.  \n",
    "U **leaf-wise** daraxt oâ€˜sishini ishlatadi (depth-wise emas), bu esa yuqori aniqlik beradi.\n",
    "\n",
    "Uning afzalliklari:\n",
    "- GPUâ€™ni qoâ€˜llaydi ğŸ’ª  \n",
    "- Categorical featureâ€™larni toâ€˜gâ€˜ridan-toâ€˜gâ€˜ri qabul qiladi  \n",
    "- Juda katta datasetlar bilan ishlashga moâ€˜ljallangan  \n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Muhim Hyperparametrlar\n",
    "\n",
    "| Parametr | Tavsif | Tavsiya qiymatlar | Natijaga taâ€™siri |\n",
    "|-----------|---------|-------------------|------------------|\n",
    "| `num_leaves` | Daraxt barglari soni | 31â€“256 | Katta â†’ kuchli model, lekin overfitting xavfi |\n",
    "| `learning_rate` | Oâ€˜rganish tezligi | 0.01â€“0.3 | Kichik â†’ sekin, lekin barqaror |\n",
    "| `n_estimators` | Daraxtlar soni | 100â€“1000 | Koâ€˜p â†’ aniqlik oshadi |\n",
    "| `max_depth` | Daraxt chuqurligi | -1 (auto) yoki 3â€“10 | Cheklash â†’ barqaror model |\n",
    "| `subsample` | Namunalar foizi | 0.5â€“1.0 | Kichik â†’ overfitting kamayadi |\n",
    "| `colsample_bytree` | Har daraxtda ustun foizi | 0.5â€“1.0 | Model xilma-xilligini oshiradi |\n",
    "| `reg_alpha` | L1 regularizatsiya (Lasso) | 0â€“10 | Katta â†’ sparse model |\n",
    "| `reg_lambda` | L2 regularizatsiya (Ridge) | 0â€“10 | Silliq, barqaror model |\n",
    "| `random_state` | Tasodifiylik nazorati | int | Takrorlanadigan natijalar |\n",
    "| `device` | Hisoblash qurilmasi | 'cpu' / 'gpu' | GPU â†’ tezroq oâ€˜qitish |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» Kod Misoli\n",
    "\n",
    "```python\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ma'lumot\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Aniqlik:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6844da8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
